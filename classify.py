
from transformers import ViTImageProcessor
from transformers import ViTForImageClassification

from pathlib import Path
from PIL import Image
import requests
import torch
import torch.nn.functional as F

# æ¨¡å‹åç¨±
MODEL_NAME = "nateraw/vit-base-food101"

# æœ¬åœ°æ¨¡å‹å„²å­˜è·¯å¾‘
MODEL_DIR = "./models/vit-base-food101"
LABELS_PATH = "./models/classes.txt"

# æª¢æŸ¥æ˜¯å¦å­˜åœ¨æœ¬åœ°æ¨¡å‹
USE_LOCAL_MODEL = Path(MODEL_DIR).exists()

# è®€å–é¡åˆ¥æ¨™ç±¤
def load_labels(label_file):
    with open(label_file, "r") as f:
        label_list = [line.strip() for line in f.readlines()]
    return {i: label_list[i] for i in range(len(label_list))}

def load_models():
    # åŠ è¼‰æ¨¡å‹å’Œç‰¹å¾µæå–å™¨
    if USE_LOCAL_MODEL:
        print("ğŸ“Œ ä½¿ç”¨æœ¬åœ°æ¨¡å‹")
        model = ViTForImageClassification.from_pretrained(MODEL_DIR)
        feature_extractor = ViTImageProcessor.from_pretrained(MODEL_DIR)
        
    else:
        print("ğŸ“Œ ä¸‹è¼‰ä¸¦ä½¿ç”¨ Hugging Face é è¨“ç·´æ¨¡å‹")
        model = ViTForImageClassification.from_pretrained(MODEL_NAME)
        feature_extractor = ViTImageProcessor.from_pretrained(MODEL_NAME)
        
        # ä¿å­˜åˆ°æœ¬åœ°
        model.save_pretrained(MODEL_DIR)
        feature_extractor.save_pretrained(MODEL_DIR)
    
    return model, feature_extractor

def preprocess_image(image_path_or_url, feature_extractor):
    if image_path_or_url.startswith("http"):
        image = Image.open(requests.get(image_path_or_url, stream=True).raw)
        
    else:
        image = Image.open(image_path_or_url)
        
    inputs = feature_extractor(images=image, return_tensors="pt")
    return inputs

def predict_food(image_path_or_url, model, feature_extractor, food101_labels):
    inputs = preprocess_image(image_path_or_url, feature_extractor)
    with torch.no_grad():
        outputs = model(**inputs)
        
    logits = outputs.logits
    probs = F.softmax(logits, dim=-1)
    predicted_class_idx = torch.argmax(probs, dim=-1).item()
    predicted_label = food101_labels[predicted_class_idx]
    confidence = probs[0, predicted_class_idx].item()
    
    print(f"ğŸ›  é æ¸¬é¡åˆ¥ç´¢å¼•: {predicted_class_idx}")
    print(f"ğŸ½ é æ¸¬é£Ÿç‰©é¡åˆ¥: {predicted_label} (ç½®ä¿¡åº¦: {confidence:.4f})")
    return predicted_label, confidence

# é æ¸¬é£Ÿç‰©é¡åˆ¥, è¿”å›å‰5å€‹æœ€å¤§ç½®ä¿¡åº¦é¡åˆ¥
def predict_top5_food(image_path_or_url, model, feature_extractor, food101_labels):
    inputs = preprocess_image(image_path_or_url, feature_extractor)
    with torch.no_grad():
        outputs = model(**inputs)

    logits = outputs.logits
    probs = F.softmax(logits, dim=-1)  # æ­¸ä¸€åŒ–æ¦‚ç‡

    # å–å¾—å‰5å€‹æœ€å¤§ç½®ä¿¡åº¦é¡åˆ¥
    top5_probs, top5_class_idxs = torch.topk(probs, k=5, dim=-1)

    # è½‰æ›ç´¢å¼•åˆ°å¯¦éš›é¡åˆ¥åç¨±
    top5_results = [(food101_labels[idx.item()], top5_probs[0][i].item()) for i, idx in enumerate(top5_class_idxs[0])]

    print(f"ğŸ“· åœ–ç‰‡: {image_path_or_url}")
    for rank, (label, conf) in enumerate(top5_results, start=1):
        print(f"ğŸ¥‡ Top {rank}: {label} (ç½®ä¿¡åº¦: {conf:.4f})")

    return top5_results

if __name__ == "__main__":
    # åŠ è¼‰é¡åˆ¥æ¨™ç±¤
    food101_labels = load_labels(LABELS_PATH)
    
    # åŠ è¼‰æ¨¡å‹èˆ‡ç‰¹å¾µæå–å™¨
    model, feature_extractor = load_models()
    
    for i in range(6):
        image_url = f"testing/{i}.jpg"
        predict_top5_food(image_url,
                          model,
                          feature_extractor,
                          food101_labels)
        