import cv2
import gradio as gr
import numpy as np
import os
from pathlib import Path
import pandas as pd
from PIL import Image
import requests
import time

from FoodSAM.semantic import main
from FoodSAM.semantic import args

# MODEL_DIR   = "./models/vit-base-food101"
# SAFETENSOR  = "./models/vit-base-food101/model.safetensors"
# LABELS_PATH = "./models/classes.txt"

SAM_INPUT_IMG  = "./output/image/input.jpg"
SAM_MASK_DIR   = "./output/image/sam_mask"
MASK_INFO_PATH = "./output/image/sam_mask_label/semantic_masks_category.txt"
SAM_MAP_DIR = "./output/image/sam_map"

def request_food101_prediction(masked_img_folder):
    url = "http://localhost:5001/classify"
    response = requests.post(url, json={"folder": masked_img_folder})
    
    if response.status_code == 200:
        results = response.json()
        for r in results:
            print(f"{r['img']} â†’ {r['label']}, {r['conf']}")
        return results
    
    else:
        print("Error:", response.text)
        return None
    
# class Classification:
    
#     def __init__(self):
#         global MODEL_DIR
#         global LABELS_PATH
#         global SAFETENSOR
        
#         self.model_dir = MODEL_DIR
#         self.labels_path = LABELS_PATH
#         self.safetensor = SAFETENSOR
        
#         self.model = None
#         self.feature_extractor = None
#         self.labels = None
        
#         self.load_model()
#         self.load_labels()
        
#     def load_model(self):
#         # åŠ è¼‰æ¨¡å‹å’Œç‰¹å¾µæå–å™¨
#         if Path(self.model_dir).exists():
#             print("ğŸ“Œ ä½¿ç”¨æœ¬åœ°æ¨¡å‹")
#             # è®€ config
#             config = ViTConfig.from_pretrained(self.model_dir)
#             self.model = ViTForImageClassification(config)
            
#             # å»ºç«‹æ¨¡å‹çµæ§‹
#             state_dict = load_file(self.safetensor)
#             self.model.load_state_dict(state_dict)
            
#             self.feature_extractor = ViTImageProcessor.from_pretrained(self.model_dir)
        
#         else:
#             print("ğŸ“Œ ä¸‹è¼‰ä¸¦ä½¿ç”¨ Hugging Face é è¨“ç·´æ¨¡å‹")

#     def load_labels(self):
#         with open(self.labels_path, "r") as f:
#             label_list = [line.strip() for line in f.readlines()]
        
#         self.labels = {i: label_list[i] for i in range(len(label_list))}
        
#     def preprocess_image(self, image_path):
#         image = Image.open(image_path)
#         inputs = self.feature_extractor(images=image, return_tensors="pt")
#         return inputs
    
#     def predict_food(self, image_path):
#         inputs = self.preprocess_image(image_path)
        
#         with torch.no_grad():
#             outputs = self.model(**inputs)
        
#         logits = outputs.logits
#         probs = F.softmax(logits, dim=-1)
#         predicted_class_idx = torch.argmax(probs, dim=-1).item()
#         predicted_label = self.labels[predicted_class_idx]
#         confidence = probs[0, predicted_class_idx].item()
        
#         print(f"ğŸ›  é æ¸¬é¡åˆ¥ç´¢å¼•: {predicted_class_idx}")
#         print(f"ğŸ½ é æ¸¬é£Ÿç‰©é¡åˆ¥: {predicted_label} (ç½®ä¿¡åº¦: {confidence:.4f})")
#         return predicted_label, confidence

#     def predict_top5_food(self, image_path):
#         inputs = self.preprocess_image(image_path)
        
#         with torch.no_grad():
#             outputs = self.model(**inputs)

#         logits = outputs.logits
#         probs = F.softmax(logits, dim=-1)  # æ­¸ä¸€åŒ–æ¦‚ç‡
        
#         # å–å¾—å‰5å€‹æœ€å¤§ç½®ä¿¡åº¦é¡åˆ¥
#         top5_probs, top5_class_idxs = torch.topk(probs, k=5, dim=-1)
    
#         # è½‰æ›ç´¢å¼•åˆ°å¯¦éš›é¡åˆ¥åç¨±
#         top5_results = [(self.labels[idx.item()], top5_probs[0][i].item()) for i, idx in enumerate(top5_class_idxs[0])]

#         print(f"ğŸ“· åœ–ç‰‡: {image_path}")
#         for rank, (label, conf) in enumerate(top5_results, start=1):
#             print(f"ğŸ¥‡ Top {rank}: {label} (ç½®ä¿¡åº¦: {conf:.4f})")
        
#         return top5_results

class Segmentation:
    
    def __init__(self):
        global SAM_INPUT_IMG
        global SAM_MASK_DIR
        global MASK_INFO_PATH
        global SAM_MAP_DIR
        
        self.sam_input_img  = SAM_INPUT_IMG
        self.sam_mask_dir   = SAM_MASK_DIR
        self.mask_info_path = MASK_INFO_PATH
        self.sam_map_dir = SAM_MAP_DIR
    
    def apply_mask(self, original_image, mask):
        if len(mask.shape) == 3:
            mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
        binary_mask = (mask == 255).astype(np.uint8)
        
        # æ“´å±•ç‚º3é€šé“
        binary_mask_3ch = np.repeat(binary_mask[:, :, np.newaxis], 3, axis=2)
        masked_image = original_image * binary_mask_3ch  # ä¿ç•™åŸåœ–åƒç´ ï¼Œå…¶ä»–è®Š0
        return masked_image

    @staticmethod
    def filter_valid_mask(df, mask_ratio):
        valid_masks = df[
            (df['category_id'] != 0) &
            (df['category_count_ratio'] > 0.9) &
            (df['mask_count_ratio'] > mask_ratio)
        ]
        return valid_masks
    
    def parse_valid_masks(self, valid_masks):
        input_img = cv2.imread(self.sam_input_img)
        
        if not Path(self.sam_map_dir).exists():
            os.mkdir(self.sam_map_dir)
        
        masked_img_list = []
        for _, row in valid_masks.iterrows():
            mask_id = row['id']
            category = row['category_name']
            
            mask_path = os.path.join(self.sam_mask_dir, f"{mask_id}.png")
            save_path = os.path.join(self.sam_map_dir,  f"{mask_id}.png")
            mask_img = cv2.imread(mask_path)
            
            if mask_img is None:
                print(f"[!] Warning: Mask {mask_path} not found.")
                continue
            
            masked_img = self.apply_mask(input_img, mask_img)
            cv2.imwrite(save_path, masked_img)
            masked_img_list.append(save_path)
        
        return masked_img_list

    def group_classify_results(self, classify_results):
        img_list = []
        group_results = []
        for data in classify_results:
            img = cv2.imread(data['img'])
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            # group_results.append((img, data['label'], data['conf']))
            img_list.append(img)
            group_results.append((data['img'], data['label'], data['conf']))
        
        return img_list, group_results

segment    = Segmentation()

def process_img(img, mask_ratio):
    start = time.time()
    print(img)
    if main(args, img):
        end = time.time()
        result_img  = "output/image/enhance_vis.png"
        result_file = "output/image/sam_mask_label/semantic_masks_category.txt"
        df = pd.read_csv(result_file)
        valid_mask = Segmentation.filter_valid_mask(df, mask_ratio)
        masked_list = segment.parse_valid_masks(valid_mask)
        
        classify_results = request_food101_prediction(segment.sam_map_dir)
        img_list, classify_results = segment.group_classify_results(classify_results)
        print(classify_results)
        
        time_cost = f"Cost: {round(end - start, 3)} s"
        
        return result_img, df, valid_mask, img_list, classify_results, time_cost
    
    else:
        return None, "é æ¸¬çµæœ: NaN"

with gr.Blocks(css="""
        .gradio-container { max-width: 1400px !important; }
        .gallery-img img { max-height: 360px !important; max-width: 360px !important; object-fit: contain; }
    """) as dietsnap:
    gr.Markdown("## ğŸ± DietSnap é£Ÿç‰©è¾¨è­˜å±•ç¤º")
    
    with gr.Row():
        with gr.Column(scale=1):
            with gr.Row():
                with gr.Column():
                    input_img = gr.Image(type="filepath", label="ğŸ“¤ ä¸Šå‚³åœ–ç‰‡")
                    mask_ratio = gr.Number(0.01, label="åˆ†å‰²æ¯”ä¾‹")
                    submit_btn = gr.Button("ğŸš€ é–‹å§‹è¾¨è­˜", variant="primary")
            
            with gr.Row():
                seg_img = gr.Image(type="numpy", label="ğŸ–¼ï¸ åˆ†å‰²åœ–ç¤º", show_label=True)
                
            with gr.Row():
                cost = gr.Text(label="â±ï¸ è™•ç†è€—æ™‚")
                
        with gr.Column(scale=2):
            
            with gr.Row():
                with gr.Column(scale=1):
                    gallery = gr.Gallery(label="ğŸ” é è¦½åœ–ç‰‡", elem_classes=["gallery-img"])
                    
                with gr.Column(scale=1):
                    cls_table = gr.Dataframe(
                        headers=["åœ–ç‰‡è·¯å¾‘", "é¡åˆ¥", "ä¿¡å¿ƒåº¦"],
                        datatype=["str", "str", "number"],
                        row_count=None,
                        label="ğŸ“Š åˆ†é¡çµæœ"
                    )
                    
            with gr.Row():
                with gr.Column(scale=1):
                    seg_table = gr.Dataframe(label="ğŸ“‹ åˆ†å‰²çµæœ", interactive=False)
                        
                with gr.Column(scale=1):
                        filter_table = gr.Dataframe(label="ğŸ“‹ éæ¿¾çµæœ", interactive=False)
     
                
    # éš±è— flag
    dietsnap.flagging = None
    input_img.change(fn=process_img, inputs=[input_img, mask_ratio], 
                     outputs=[seg_img, seg_table, filter_table, gallery, cls_table, cost])
    
dietsnap.launch()
# dietsnap = gr.Interface(fn=process_img,
#                         inputs=gr.Image(type="filepath", label="ä¸Šå‚³åœ–ç‰‡"),
#                         outputs=[gr.Image(type="numpy", label="åˆ†å‰²åœ–ç¤º"),
#                                  gr.Dataframe(label="åˆ†å‰²çµæœ"),
#                                  gr.Dataframe(label="éæ¿¾çµæœ"),
#                                  gr.Gallery(label="é è¦½åœ–ç‰‡", height="auto"),
#                                  gr.Dataframe(
#                                      headers=["åœ–ç‰‡è·¯å¾‘", "é¡åˆ¥", "ä¿¡å¿ƒåº¦"],
#                                      datatype=["str", "str", "number"],
#                                      row_count=None,
#                                      label="åˆ†é¡çµæœ"
#                                  ),
#                                  gr.Text(label="è€—æ™‚")],
#                         title="DietSnap é£Ÿç‰©è¾¨è­˜åˆæ­¥å±•ç¤º")
